# Crawler

A Web Crawler for the newhaven.edu domain. **Web crawler**, sometimes called a spider or spiderbot and often shortened to crawler, is an Internet bot that systematically browses the World Wide Web, typically operated by search engines for the purpose of Web indexing.

This Project was developed using Pytho and a Python library **Beautiful Soup**. Beautiful Soup is a Python library for pulling data out of HTML and XML files. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.

# Requirements

* Python3
* BeautifulSoup4
* Requests-HTML
* Colorama

# Install Dependencies

> `pip install requirements`

## Usage

* Download the Code.
* pip install virtualenv on your Desktop using CLI.
* Open the source directory of the Project.
* Install all the dependecies in your virtual enviornment using the command
> `pip install -r requirements.txt`
* Execute the Code using the following command
> `python crawler.py https://www.newhaven.edu/search`

## Images

![image1](https://user-images.githubusercontent.com/78525041/117524233-b0b60a80-af8a-11eb-848b-1e1ddf710422.png)
![image2](https://user-images.githubusercontent.com/78525041/117524234-b14ea100-af8a-11eb-88c3-0fffd7eeea26.png)
![image3](https://user-images.githubusercontent.com/78525041/117524235-b1e73780-af8a-11eb-9500-22dc1465f0ff.png)
